{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3528ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7327048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "X=torch.randn(128,64,512) #  随机生成一个形状为(batch=128,time=64,dimension=512)的三维张量\n",
    "print(X.shape)\n",
    "\n",
    "special_tokens = [\"<UNK>\", \"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
    "vocab = {\"<UNK>\":0,\"<PAD>\":1,\"<SOS>\":2,\"<EOS>\":3}  #未知词，填充标记，序列开始，序列结束\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189b4b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model=512 #每个词元被表示成一个 512 维的向量\n",
    "n_head=8 #注意力头数目"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b786d5d",
   "metadata": {},
   "source": [
    "# Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08efde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词嵌入层：将序列中的每个离散词元，分别转化为一个d_model维的向量，最终得到一个词向量序列\n",
    "class TokenEmbedding(nn.Embedding):\n",
    "    def __init__(self,vocab_size,d_model): #vocab_size:词汇表大小(不同的token总数)\n",
    "        super(TokenEmbedding,self).__init__(vocab_size,d_model,padding_idx=1) \n",
    "# 输入形状为(batch_size,seq_len)的词元索引序列\n",
    "# 输出形状为(batch_size,seq_len,d_model)的词向量序列\n",
    "#padding_idx=1确保索引为1的填充符号始终映射为全 0 向量，避免其干扰模型对有效词元的学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be50b117",
   "metadata": {},
   "source": [
    "## position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2342e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self,d_model,maxlen,device):\n",
    "        super(PositionalEmbedding,self).__init__()\n",
    "        self.encoding=torch.zeros(maxlen,d_model,device=device) #创建一个全零的二维张量，形状为(maxlen,d_model)\n",
    "        self.encoding.requires_grad_(False)  #不使用梯度\n",
    "        \n",
    "        # 生成位置索引(0到maxlen-1)\n",
    "        pos=torch.arange(0,maxlen,device=device) #arange：生成等差数列的张量\n",
    "        pos=pos.float().unsqueeze(1) #在第1维度插入新维度\n",
    "        #生成索引维度(步长为2，对应偶数维度)\n",
    "        _2i=torch.arange(0,d_model,2,device=device)\n",
    "        # 偶数维度\n",
    "        self.encoding[:,0::2]=torch.sin(pos/(10000**(_2i/d_model)))\n",
    "        # 奇数维度\n",
    "        self.encoding[:,1::2]=torch.cos(pos/(10000**(_2i/d_model)))\n",
    "\n",
    "    def forward(self,x):\n",
    "        seq_len=x.shape[1] # x 是词向量序列，形状为 (batch_size, seq_len, d_model)，取实际序列长度\n",
    "        return self.encoding[:seq_len,:] # 返回前 seq_len 个位置的嵌入，形状为 (seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2255d3",
   "metadata": {},
   "source": [
    "## total embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f097fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model,maxlen,drop_prob,device):\n",
    "        super(TransformerEmbedding,self).__init__()\n",
    "        self.token=TokenEmbedding(vocab_size,d_model)\n",
    "        self.position=PositionalEmbedding(d_model,maxlen,device)\n",
    "        self.drop_out=nn.Dropout(p=drop_prob) #训练时随机失活部分元素，防止过拟合\n",
    "\n",
    "    def forward(self,x):\n",
    "        token=self.token(x)\n",
    "        position=self.position(x)\n",
    "        return self.drop_out(token+position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96632389",
   "metadata": {},
   "source": [
    "## layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349b5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,d_model,eps=1e-10):\n",
    "        super(LayerNorm,self).__init__()\n",
    "        self.gamma=nn.Parameter(torch.ones(d_model))\n",
    "        self.beta=nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps=eps\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean=x.mean(-1,keepdim=True)\n",
    "        var=x.var(-1,unbiased=False,keepdim=True)\n",
    "        out=(x-mean)/torch.sqrt(var+self.eps)\n",
    "        out=self.gamma*out+self.beta\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2685e",
   "metadata": {},
   "source": [
    "## FFN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55674562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, hidden, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05cdb5e",
   "metadata": {},
   "source": [
    "## 多头自注意力机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f49f3b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0106, -0.0231,  0.0562,  ...,  0.0226,  0.0348,  0.0099],\n",
      "         [-0.0207, -0.0209,  0.0083,  ..., -0.0014,  0.0652,  0.0396],\n",
      "         [ 0.0005, -0.0284,  0.0429,  ...,  0.0340,  0.0317,  0.0193],\n",
      "         ...,\n",
      "         [-0.0141, -0.0278,  0.0492,  ..., -0.0163,  0.0360,  0.0084],\n",
      "         [-0.0141, -0.0377,  0.0528,  ...,  0.0165,  0.0317,  0.0290],\n",
      "         [-0.0034, -0.0062,  0.0295,  ..., -0.0211,  0.0501,  0.0037]],\n",
      "\n",
      "        [[ 0.0986, -0.0874,  0.0420,  ..., -0.0896,  0.0606, -0.0016],\n",
      "         [ 0.0813, -0.1199,  0.0089,  ..., -0.0673,  0.0433,  0.0156],\n",
      "         [ 0.0854, -0.1015,  0.0271,  ..., -0.0689,  0.0559, -0.0075],\n",
      "         ...,\n",
      "         [ 0.0796, -0.1037, -0.0089,  ..., -0.0322,  0.0627,  0.0050],\n",
      "         [ 0.0801, -0.1134, -0.0015,  ..., -0.0391,  0.0422,  0.0065],\n",
      "         [ 0.1224, -0.1153,  0.0382,  ..., -0.0757,  0.0542,  0.0064]],\n",
      "\n",
      "        [[-0.0261, -0.0028, -0.0192,  ...,  0.0495, -0.0141, -0.0031],\n",
      "         [-0.0122, -0.0336, -0.0498,  ...,  0.0295, -0.0322, -0.0245],\n",
      "         [-0.0084, -0.0366, -0.0045,  ...,  0.0369, -0.0070, -0.0024],\n",
      "         ...,\n",
      "         [-0.0198, -0.0080, -0.0323,  ...,  0.0317, -0.0146, -0.0227],\n",
      "         [-0.0411, -0.0163, -0.0134,  ...,  0.0108, -0.0203, -0.0062],\n",
      "         [-0.0257, -0.0186, -0.0343,  ...,  0.0282, -0.0032,  0.0036]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0727,  0.0115,  0.0802,  ...,  0.0716,  0.0190,  0.0199],\n",
      "         [ 0.0761,  0.0267,  0.0745,  ...,  0.1007, -0.0013,  0.0230],\n",
      "         [ 0.0444, -0.0121,  0.0586,  ...,  0.0640, -0.0130,  0.0094],\n",
      "         ...,\n",
      "         [ 0.0378,  0.0058,  0.0666,  ...,  0.0928,  0.0065,  0.0119],\n",
      "         [ 0.0539, -0.0234,  0.0694,  ...,  0.0819,  0.0019,  0.0019],\n",
      "         [ 0.0408, -0.0155,  0.0741,  ...,  0.0575,  0.0216, -0.0031]],\n",
      "\n",
      "        [[-0.0271,  0.0025,  0.0017,  ...,  0.0216,  0.0013, -0.0348],\n",
      "         [-0.0303, -0.0182,  0.0164,  ...,  0.0435, -0.0070, -0.0419],\n",
      "         [-0.0461,  0.0217,  0.0657,  ...,  0.0146,  0.0251, -0.0053],\n",
      "         ...,\n",
      "         [-0.0393,  0.0126,  0.0388,  ...,  0.0204,  0.0071, -0.0499],\n",
      "         [-0.0634,  0.0092,  0.0396,  ...,  0.0131, -0.0033, -0.0362],\n",
      "         [-0.0664,  0.0289,  0.0375,  ...,  0.0255,  0.0216, -0.0405]],\n",
      "\n",
      "        [[ 0.0242, -0.0782,  0.0372,  ..., -0.0356,  0.0187, -0.0167],\n",
      "         [ 0.0051, -0.0823,  0.0450,  ..., -0.0031,  0.0235, -0.0218],\n",
      "         [ 0.0229, -0.1078,  0.0148,  ..., -0.0216,  0.0224, -0.0129],\n",
      "         ...,\n",
      "         [ 0.0268, -0.0589,  0.0220,  ..., -0.0572,  0.0185,  0.0031],\n",
      "         [ 0.0177, -0.1023, -0.0007,  ..., -0.0314,  0.0468, -0.0138],\n",
      "         [ 0.0646, -0.0906,  0.0509,  ..., -0.0398,  0.0301, -0.0185]]],\n",
      "       grad_fn=<ViewBackward0>) torch.Size([128, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "class Multi_head_attention(nn.Module):\n",
    "    def __init__(self,d_model,n_head)->None:  #->表示函数无返回值  d_model:模型的隐藏层维度 n_head:注意力头的数量\n",
    "        super(Multi_head_attention,self).__init__()\n",
    "        # 将传入的参数保存为类属性，后续在forward中使用\n",
    "        self.n_head=n_head\n",
    "        self.d_model=d_model\n",
    "\n",
    "        #创建三个线性变换层，将输入向量投影到QKV空间\n",
    "        self.w_q=nn.Linear(d_model,d_model)\n",
    "        self.w_k=nn.Linear(d_model,d_model)\n",
    "        self.w_v=nn.Linear(d_model,d_model)\n",
    "\n",
    "        # 所有头的输出拼接后仍为d_model\n",
    "        self.w_combine=nn.Linear(d_model,d_model) #线性映射层\n",
    "        self.softmax=nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self,q,k,v,mask=None):\n",
    "        batch,time,dimension=q.shape\n",
    "        n_d=self.d_model//self.n_head\n",
    "        q,k,v=self.w_q(q),self.w_k(k),self.w_v(v)\n",
    "        #把向量拆分成多个头(batch,time,dimension)->(batch,time,n_head,n_d)\n",
    "        q=q.view(batch,time,self.n_head,n_d).permute(0,2,1,3)\n",
    "        k=k.view(batch,time,self.n_head,n_d).permute(0,2,1,3)\n",
    "        v=v.view(batch,time,self.n_head,n_d).permute(0,2,1,3)\n",
    "     \n",
    "        score=q@k.transpose(2,3)/math.sqrt(n_d)\n",
    "        if mask is not None:\n",
    "\n",
    "            # mask=torch.tril(torch.ones(time,time,dtype=bool))\n",
    "            score=score.masked_fill(mask==0,float(\"-inf\"))\n",
    "\n",
    "        score=self.softmax(score)@v\n",
    "\n",
    "        score=score.permute(0,2,1,3).contiguous().view(batch,time,dimension)\n",
    "\n",
    "        output=self.w_combine(score)\n",
    "        return output\n",
    "    \n",
    "attention=Multi_head_attention(d_model,n_head)\n",
    "output=attention(X,X,X)\n",
    "print(output,output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a68384",
   "metadata": {},
   "source": [
    "## encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "350303c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,ffn_hidden,n_head,drop_prob)->None:\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.attention=Multi_head_attention(d_model,n_head)\n",
    "        self.norm1=LayerNorm(d_model)\n",
    "        self.drop1=nn.Dropout(drop_prob)\n",
    "\n",
    "        self.ffn=PositionwiseFeedForward(d_model,ffn_hidden,drop_prob)\n",
    "        self.norm2=LayerNorm(d_model)\n",
    "        self.drop2=nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        _x=x\n",
    "        x=self.attention(x,x,x,mask)\n",
    "        \n",
    "        x=self.drop1(x)\n",
    "        x=self.norm1(x+_x)\n",
    "        \n",
    "        _x=x\n",
    "        x=self.ffn(x)\n",
    "\n",
    "        x=self.drop2(x)        \n",
    "        x=self.norm2(x+_x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b75f0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,ffn_hidden,n_head,drop_prob):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.attention=Multi_head_attention(d_model,n_head)\n",
    "        self.norm1=LayerNorm(d_model)\n",
    "        self.dropout1=nn.Dropout(drop_prob)\n",
    "\n",
    "        self.cross_attention=Multi_head_attention(d_model,n_head)\n",
    "        self.norm2=LayerNorm(d_model)\n",
    "        self.dropout2=nn.Dropout(drop_prob)\n",
    "\n",
    "        self.ffn=PositionwiseFeedForward(d_model,ffn_hidden,drop_prob)\n",
    "        self.norm3=LayerNorm(d_model)\n",
    "        self.dropout3=nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self,dec,enc,time_mask,s_mask):\n",
    "        _x=dec\n",
    "        x=self.attention(dec,dec,dec,time_mask) # 下三角掩码（因果掩码）\n",
    "\n",
    "        x=self.dropout1(x)\n",
    "        x=self.norm1(x+_x)\n",
    "\n",
    "        if enc is not None:\n",
    "            _x=x\n",
    "            x=self.cross_attention(x,enc,enc,s_mask) #位置掩码\n",
    "\n",
    "            x=self.dropout2(x)\n",
    "            x=self.norm2(x+_x)\n",
    "\n",
    "        #前馈网络 + 残差连接 + 层归一化\n",
    "        _x=x\n",
    "        x=self.ffn(x)\n",
    "        x=self.dropout3(x)\n",
    "        x=self.norm3(x+_x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e02a3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,env_voc_size,max_len,d_model,ffn_hidden,n_head,n_layer,drop_prob,device):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding = TransformerEmbedding(\n",
    "            env_voc_size, d_model, max_len, drop_prob, device\n",
    "        )\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                EncoderLayer(d_model, ffn_hidden, n_head, drop_prob)\n",
    "                for _ in range(n_layer)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, s_mask):\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, s_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e1fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dec_voc_size,max_len,d_model,ffn_hidden,n_head,n_layer,drop_prob,device):\n",
    "        super(Decoder,self).__init__()\n",
    "\n",
    "        self.embedding=TransformerEmbedding(dec_voc_size, d_model, max_len, drop_prob, device)\n",
    "\n",
    "        self.layers=nn.ModuleList(\n",
    "            [DecoderLayer(d_model,ffn_hidden,n_head,drop_prob)for _ in range(n_layer)] \n",
    "        )\n",
    "        self.fc=nn.Linear(d_model,dec_voc_size)\n",
    "\n",
    "    def forward(self,dec,enc,time_mask,s_mask):\n",
    "        dec=self.embedding(dec)\n",
    "        for layer in self.layers:\n",
    "            dec=layer(dec,enc,time_mask,s_mask)\n",
    "        dec=self.fc(dec)\n",
    "        return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f155263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_pad_idx,trg_pad_idx,enc_voc_size,dec_voc_size,max_len,d_model,n_head,ffn_hidden,n_layers,drop_prob,device):\n",
    "        super(Transformer,self).__init__()\n",
    "\n",
    "        self.encoder=Encoder(enc_voc_size,max_len,d_model,ffn_hidden,n_head,n_layers,drop_prob,device)\n",
    "        self.decoder = Decoder(dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device)\n",
    "\n",
    "        self.src_pad_idx=src_pad_idx\n",
    "        self.trg_pad_idx=trg_pad_idx\n",
    "        self.device=device\n",
    "\n",
    "    def make_pad_mask(self,q,k,pad_idx_q,pad_idx_k):\n",
    "        len_q,len_k=q.size(1),k.size(1)\n",
    "\n",
    "        # 维度(batch,time,len_q,len_k)\n",
    "        q=q.ne(pad_idx_q).unsqueeze(1).unsqueeze(3)\n",
    "        q=q.repeat(1,1,1,len_k)\n",
    "\n",
    "        k=k.ne(pad_idx_k).unsqueeze(1).unsqueeze(3)\n",
    "        k=k.repeat(1,1,len_q,1)\n",
    "\n",
    "        mask=q&k  #全一则一\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def make_causal_mask(self,q,k):\n",
    "        len_q,len_k=q.size(1),k.size(1)\n",
    "        mask=torch.tril(torch.ones(len_q,len_k)).type(torch.BoolTensor).to(self.device)\n",
    "        return mask\n",
    "    \n",
    "    def forward(self,src,trg):\n",
    "        src_mask=self.make_pad_mask(src,src,self.src_pad_idx,self.src_pad_idx)\n",
    "        trg_mask=self.make_pad_mask(trg,trg,self.trg_pad_idx,self.trg_pad_idx)*self.make_causal_mask(trg,trg)\n",
    "        src_trg_mask=self.make_pad_mask(trg,src,self.trg_pad_idx,self.src_pad_idx)\n",
    "\n",
    "        enc=self.encoder(src,src_mask)\n",
    "        output=self.decoder(trg,enc,trg_mask,src_trg_mask)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f313232",
   "metadata": {},
   "source": [
    "## 形状变化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fe30d",
   "metadata": {},
   "source": [
    "<img src=\"形状变化.jpg\" alt=\"图片描述\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac9ca0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
